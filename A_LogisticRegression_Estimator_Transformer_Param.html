<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>LogisticRegression_Estimator_Transformer_Param - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/img/favicon.ico"/>
<script>window.settings = {"enableUsageDeliveryConfiguration":false,"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableDynamicAutoCompleteResourceLoading":false,"enableClusterMetricsUI":true,"allowWhitelistedIframeDomains":true,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableReservoirTableUI":true,"enableClearStateFeature":true,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"enableAttachExistingCluster":true,"resetJobListOnConnect":true,"serverlessDefaultSparkVersion":"latest-stable-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","showS3TableImportOption":true,"maxEbsVolumesPerInstance":10,"enableRStudioUI":false,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"sqlAclsEnabledMap":{"spark.databricks.acl.enabled":"true","spark.databricks.acl.sqlOnly":"true"},"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableWorkspaceBrowserSorting":true,"enableSentryLogging":true,"enableFindAndReplace":true,"disallowUrlImportExceptFromDocs":false,"defaultStandardClusterModel":{"cluster_name":"","node_type_id":"dev-tier-node","spark_version":"4.0.x-scala2.11","num_workers":0,"aws_attributes":{"first_on_demand":0,"availability":"ON_DEMAND","zone_id":"us-west-2c","spot_bid_price_percent":100},"autotermination_minutes":120,"default_tags":{"Vendor":"Databricks","Creator":"bombatkar.vivek@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableBitbucketCloud":true,"shouldShowCommandStatus":true,"createTableInNotebookS3Link":{"url":"https://docs.databricks.com/_static/notebooks/data-import/s3.html","displayName":"S3","workspaceFileName":"S3 Example"},"sanitizeHtmlResult":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"useAutoscalingByDefault":false,"enableAzureToolbar":false,"fileStoreBase":"FileStore","enableEmailInAzure":false,"enableRLibraries":true,"enableTableAclsConfig":false,"enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":true,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"checkBeforeAddingAadUser":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"createTableInNotebookDBFSLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/dbfs.html","displayName":"DBFS","workspaceFileName":"DBFS Example"},"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"allowStyleInSanitizedHtml":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db6-rc-scala2.10","displayName":"Spark 2.1.1-db6 RC (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.10","displayName":"3.0 RC (Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-gpu-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-22756288786762d246bac1381e4f44610a4c2c3135c717c5ac3661822a723f1c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db5-rc-scala2.11","displayName":"Spark 2.1.1-db5 RC (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-7ce07ae16a775d917d6748d2075807565c157286f4f5957c1b77275b3b2a9bc4","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-scala2.10","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-86a9b375074f5afad339e70230ec0ec265c4cefbd280844785fab3bcde5869f9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1, deprecated)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.1-db6-scala2.10","displayName":"Spark 2.1.1-db6 (Scala 2.10)","packageLabel":"spark-image-4efc0c94e152791782f2cb865ac1eb3c11985a2671a77e6ef930f9718851459d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-ab147bdd6662fef83fa48e41d909aa045422585552758dc667f1971876c4486f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.5.x-rc-scala2.11","displayName":"3.5.3 RC (Scala 2.11)","packageLabel":"spark-image-7d831cf1ceae80596e0942c6b4bc033b551ba4936bef02ab1028c6245bb9b260","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-d613235f93e0f29838beb2079a958c02a192ed67a502192bc67a8a5f2fb37f35","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-rc-scala2.11","displayName":"4.0.1 RC (Scala 2.11)","packageLabel":"spark-image-987e09834cd3f48e1ba1a824d98e0bcda902fd97ff9b7ab4bdb87c3972cf6657","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"latest-stable-gpu-scala2.11","displayName":"Latest stable (GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-f91cb0b3822c6641a9d346ef6c149118fb859b5e511ee01c31e958892ba23c7a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-25dac86138b91b354c5882419df5c45cd3695fb36b3a14ad63ff459cd7ae28b8","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.2.x-scala2.10","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-experimental-scala2.10","displayName":"Latest experimental (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-gpu-scala2.11","displayName":"3.4.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-56d2d0a4e40979a774d34cb0cd8b20392069c194b5bc387f391a1f1260d4db20","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"4.0.x-gpu-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, GPU, Scala 2.11)","packageLabel":"spark-image-b543c0700f83413b0055359ea9feaf285f2e2f3350fb7f301ea0e18b018b5cb5","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-rc-scala2.10","displayName":"Spark 2.1.1-db4 RC (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-rc-scala2.10","displayName":"Spark 2.1.1-db5 RC (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.11","displayName":"Latest RC (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-ac66411ea126b66e63bdfa9b8fa23571c184bd1df9b8324ea671b9c97d71a667","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS","SUPPORTS_RSTUDIO"]},{"key":"latest-stable-scala2.11","displayName":"Latest stable (Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db6-rc-scala2.11","displayName":"Spark 2.1.1-db6 RC (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-0adabd34980ecfcbc6a48ac5c9e3a954cf5ec3a53a3300ae0e392c03299d89ca","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.11","displayName":"3.3.3 RC (Scala 2.11)","packageLabel":"spark-image-2ca6b933a832ab5102873c4f85681ce6b602e714faee97af6b5206c81ed33d19","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-rc-scala2.11","displayName":"3.4.3 RC (Scala 2.11)","packageLabel":"spark-image-18ad63ac1ae638ceda9f0cf7d17aabd82d4899758aceb4f2201d4d3dfc9e55f1","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.3.x-rc-gpu-scala2.11","displayName":"3.3.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-70c6c032855a9317f0985d6b5e38bd87ada0044205660d512ee8667a53e6da19","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"next-major-version-scala2.11","displayName":"Next major version (4.0 snapshot, Scala 2.11)","packageLabel":"spark-image-04bb47b0bae8165f760972376ce05083bc6102645f3f3851cd1cdf9cba13d6fe","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.1.1-db4-rc-scala2.11","displayName":"Spark 2.1.1-db4 RC (Scala 2.11)","packageLabel":"spark-image-62365f2d91529bc1128d8968f33d07f5b8d75cf7305de9455bc970e6e1fecbb4","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-fe8300ae2b3bf12c79ce76d7e9d2d03995e58d1497cfb6c0d3172efb630cb2df","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"4.0.x-rc-gpu-scala2.11","displayName":"4.0.1 RC (GPU, Scala 2.11)","packageLabel":"spark-image-65799b50fc041aa7d9cfa53f0803d23be8e7430a44896110425ce411d756ecf9","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.10","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.3.x-rc-scala2.10","displayName":"3.3.3 RC (Scala 2.10)","packageLabel":"spark-image-3fff044e0a494f3f497206b8073657994aef53c820204cf74b0befa65293af0f","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-0112f566715b00d5aceb1b98543285bcb3a0f38174b86abd1c096c3e861043eb","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-scala2.10","displayName":"Latest RC (Scala 2.10)","packageLabel":"spark-image-ec81b6840af02ee2321dd8dfe2587437bbcddf024d4ae287f326a98fac406a6c","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-stable-scala2.10","displayName":"[DEPRECATED] Latest stable (Scala 2.10)","packageLabel":"spark-image-5e4f1f2feb631875a6036dffb069ec14b436939b5efe0ecb3ff8220c835298d6","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.4.x-rc-scala2.10","displayName":"3.4.3 RC (Scala 2.10)","packageLabel":"spark-image-6c9b7927775c3fe7669630142c6351b1564a93331c7b4d0da3744262499b0ca1","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"3.1.x-rc-scala2.10","displayName":"3.1 RC (Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-07da7d24ad964d7a43f53bd9feac55de7df890ef6e5f6bac8975fb7aa3e2a0a7","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.4.x-gpu-scala2.11","displayName":"3.4 (includes Apache Spark 2.2.0, GPU, Scala 2.11)","packageLabel":"spark-image-66d1366768039140a9f5409f3bab414cb7477ebd8d4bbf8b32cb885120f9f705","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1, deprecated)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-gpu-scala2.11","displayName":"Latest experimental (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-8ba4c75f831af5dc66b2bb8ea82bab3b699fba8b6651ec416febec923541304d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_RSTUDIO"]},{"key":"3.2.x-rc-scala2.11","displayName":"3.2 RC (Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"2.2.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.0.x-scala2.11","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-177f3f02a6a3432d30068332dc857b9161345bdd2ee8a2d2de05bb05cb4b0f4c","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.1.x-scala2.11","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-1f615934d3e248da8dcfb3e03bd8d92e933a17845fedb7cce12af2a0220ba6a2","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-rc-scala2.11","displayName":"3.0 RC (Scala 2.11)","packageLabel":"spark-image-cdfb5c6299de6a2f4f5b75e8def2d11faa2026a8354185434873ec4612916663","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-rc-gpu-scala2.11","displayName":"3.5.3 RC (GPU, Scala 2.11)","packageLabel":"spark-image-69fdc63b00be4a3877718d695191fe581f68e1d2be71faba7e7c61825006d208","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.1.x-scala2.10","displayName":"3.1 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-c6b477859faf291f56ac2dcbe6f6693d60e403c12dfcac58892b4014614363c3","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.3.x-scala2.11","displayName":"3.3 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-46cc39a9afa43fbd7bfa9f4f5ed8d23f658cd0b0d74208627243222ae0d22f8d","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"next-major-version-gpu-scala2.11","displayName":"Next major version (4.0 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-41e21a0db3b77bc857f10358917ccbf5fbd85290e8429c2176a5fc7a29ce4f18","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-gpu-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, GPU, Scala 2.11)","packageLabel":"spark-image-7a1e78fbfc4d1645e7478daa28377389b900aec38764df46bd836c1a9925499b","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":[]},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1, deprecated)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-c8547fab0cc66b918f9a64c7e35532de209d0d0e06da6078ad787ec718b37e7b","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.1-db6-scala2.11","displayName":"Spark 2.1.1-db6 (Scala 2.11)","packageLabel":"spark-image-0067951c626cad90625cce4d2dcf3e00a1029375f8e5470d2330036d0d3c505f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-b512ba976616af10269438701339a9bd5a97cc386737c6ecffdda5fb31c3cf20","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.5.x-scala2.11","displayName":"3.5 LTS (includes Apache Spark 2.2.1, Scala 2.11)","packageLabel":"spark-image-c919ecd682175957255cbc87041d82633406312f7b74e018e165c4fe94943b5f","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.1.x-rc-scala2.11","displayName":"3.1 RC (Scala 2.11)","packageLabel":"spark-image-0d3a99d46a4c55642850b5eba9aad3b56ffb9adbe8c8893403eba834399960fc","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]},{"key":"latest-experimental-scala2.11","displayName":"Latest experimental (4.1 snapshot, Scala 2.11)","packageLabel":"spark-image-ac66411ea126b66e63bdfa9b8fa23571c184bd1df9b8324ea671b9c97d71a667","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS","SUPPORTS_RSTUDIO"]},{"key":"3.2.x-scala2.11","displayName":"3.2 (includes Apache Spark 2.2.0, Scala 2.11)","packageLabel":"spark-image-3b22b5c8d5577281bcca8dd6ef07553fb32b3b99ab977f8bdb7238f850ece887","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-fdad9ef557700d7a8b6bde86feccbcc3c71d1acdc838b0fd299bd19956b1076e","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"3.0.x-scala2.10","displayName":"3.0 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-2fdca45e0fcac7081823a5faef4f25d6fc909d11c44eca82e1dd18e9d2ef2859","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":[]},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-0ea14d4a8a71de38872dd398b1139d55302680cfe3e9da217576c8304cd19b24","upgradable":true,"deprecated":true,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"latest-rc-gpu-scala2.11","displayName":"Latest RC (4.1 snapshot, GPU, Scala 2.11)","packageLabel":"spark-image-8ba4c75f831af5dc66b2bb8ea82bab3b699fba8b6651ec416febec923541304d","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_RSTUDIO"]},{"key":"3.5.x-rc-scala2.10","displayName":"3.5.3 RC (Scala 2.10)","packageLabel":"spark-image-d9bd3a87e97eeeaf0167aa61b0d1c7b4ee0f19c33c16781dbc130f3edb09c0ec","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},{"key":"3.4.x-scala2.10","displayName":"3.4 (includes Apache Spark 2.2.0, Scala 2.10)","packageLabel":"spark-image-867d7300605c0c54b2b1394d1bba7b88b28ed5841b3575253cded34db6ce6454","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION"]},{"key":"3.2.x-rc-scala2.10","displayName":"3.2 RC (Scala 2.10)","packageLabel":"spark-image-e50cbe4c0b0ad46930872eff4b69665890fd6a170e2b1a3e48c1cdea5823fd86","upgradable":true,"deprecated":false,"customerVisible":false,"capabilities":[]}],"enablePresentationMode":false,"enableClearStateAndRunAll":true,"enableTableAclsByTier":false,"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"jobsUnreachableThresholdMillis":60000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"createTableInNotebookImportedFileLink":{"url":"https://docs.databricks.com/_static/notebooks/data-import/imported-file.html","displayName":"Imported File","workspaceFileName":"Imported File Example"},"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","showDbuPricing":true,"databricksDocsBaseHostname":"docs.databricks.com","defaultNodeTypeToPricingUnitsMap":{"Standard_E64s_v3":16,"r3.2xlarge":2,"i3.4xlarge":4,"class-node":1,"m4.2xlarge":1.5,"Standard_D11_v2":0.5,"r4.xlarge":1,"m4.4xlarge":3,"Standard_DS5_v2":3,"Standard_D2s_v3":0.5,"Standard_DS4_v2_Promo":1.5,"Standard_DS14":4,"Standard_DS11_v2_Promo":0.5,"r4.16xlarge":16,"Standard_NC6":2,"Standard_DS11":0.5,"Standard_D2_v3":0.5,"Standard_DS14_v2_Promo":4,"Standard_D64s_v3":12,"p2.8xlarge":16,"m4.10xlarge":8,"Standard_D8s_v3":1.5,"Standard_E32s_v3":8,"Standard_DS3":0.75,"Standard_DS2_v2":0.5,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"Standard_L8s":2,"Standard_D13_v2":2,"Standard_DS13_v2_Promo":2,"Standard_E4s_v3":1,"Standard_D3_v2":0.75,"Standard_NC24":8,"Standard_NC24r":8,"Standard_DS15_v2":5,"Standard_D16s_v3":3,"Standard_D5_v2":3,"Standard_E8s_v3":2,"Standard_DS2_v2_Promo":0.5,"c3.8xlarge":4,"Standard_D4_v3":0.75,"Standard_E2s_v3":0.5,"Standard_D32_v3":6,"Standard_DS3_v2":0.75,"r3.4xlarge":4,"Standard_DS4":1.5,"i2.4xlarge":6,"Standard_DS3_v2_Promo":0.75,"m4.xlarge":0.75,"r4.8xlarge":8,"Standard_D14_v2":4,"Standard_H16":4,"Standard_NC12":4,"Standard_DS14_v2":4,"r4.large":0.5,"Standard_D15_v2":5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"Standard_D12_v2":1,"i3.large":0.75,"memory-optimized":1,"m4.large":0.4,"Standard_D16_v3":3,"Standard_F4s":0.5,"p2.16xlarge":24,"i3.8xlarge":8,"Standard_D32s_v3":6,"i3.16xlarge":16,"Standard_DS12_v2":1,"Standard_L32s":8,"Standard_D4s_v3":0.75,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS12_v2_Promo":1,"Standard_DS13_v2":2,"c3.2xlarge":1,"Standard_L4s":1,"Standard_F16s":2,"c4.2xlarge":1,"Standard_L16s":4,"i2.xlarge":1.5,"Standard_DS2":0.5,"compute-optimized":1,"c4.4xlarge":2,"Standard_DS5_v2_Promo":3,"Standard_D64_v3":12,"Standard_D2_v2":0.5,"Standard_D8_v3":1.5,"i3.2xlarge":2,"Standard_E16s_v3":4,"Standard_F8s":1,"c3.4xlarge":2,"Standard_D4_v2":1.5,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"Standard_DS4_v2":1.5,"c4.8xlarge":4,"i3.xlarge":1,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"tableFilesBaseFolder":"/tables","enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableClusterAppsUIOnServerless":false,"enableEBSVolumesUI":false,"homePageWelcomeMessage":"Welcome to ","metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.69.54","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"useAADLogin":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":true,"enableStrongPassword":false,"showReleaseNote":true,"displayDefaultContainerMemoryGB":6,"broadenedEditPermission":false,"disableS3TableImport":false,"enableArrayParamsEdit":true,"deploymentMode":"production","useSpotForWorkers":true,"removePasswordInAccountSettings":false,"preferStartTerminatedCluster":false,"enableUserInviteWorkflow":true,"createTableConnectorOptionLinks":[{"url":"https://docs.databricks.com/_static/notebooks/redshift.html","displayName":"Amazon Redshift","workspaceFileName":"Amazon Redshift Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-kinesis.html","displayName":"Amazon Kinesis","workspaceFileName":"Amazon Kinesis Example"},{"url":"https://docs.databricks.com/_static/notebooks/data-import/jdbc.html","displayName":"JDBC","workspaceFileName":"JDBC Example"},{"url":"https://docs.databricks.com/_static/notebooks/cassandra.html","displayName":"Cassandra","workspaceFileName":"Cassandra Example"},{"url":"https://docs.databricks.com/_static/notebooks/structured-streaming-etl-kafka.html","displayName":"Kafka","workspaceFileName":"Kafka Example"},{"url":"https://docs.databricks.com/_static/notebooks/redis.html","displayName":"Redis","workspaceFileName":"Redis Example"},{"url":"https://docs.databricks.com/_static/notebooks/elasticsearch.html","displayName":"Elasticsearch","workspaceFileName":"Elasticsearch Example"}],"enableStaticNotebooks":true,"enableNewLineChart":true,"sandboxForUrlSandboxFrame":"allow-scripts allow-popups allow-popups-to-escape-sandbox allow-forms","enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterEdit":true,"enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"enableCreateClusterOnAttach":true,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"defaultMinWorkers":2,"commandStatusDebounceMaxWait":1000,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableExperimentalCharts":false,"defaultMaxWorkers":8,"enableWorkspaceAclsConfig":false,"serverlessRunPythonAsLowPrivilegeUser":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":true,"enableNewDashboardViews":true,"enableJobListPermissionFilter":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"4.0.x-scala2.11","displayName":"4.0 (includes Apache Spark 2.3.0, Scala 2.11)","packageLabel":"spark-image-fc9368293e1b3b6c37181d7af3123a4b9de5f7fa03cfd6dfaa038753256380c9","upgradable":true,"deprecated":false,"customerVisible":true,"capabilities":["SUPPORTS_END_TO_END_ENCRYPTION","SUPPORTS_TABLE_ACLS"]},"enableNewLineChartParams":false,"deprecatedEnableStructuredDataAcls":false,"enableCustomSpotPricing":false,"enableRStudioFreeUI":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":120,"useDevTierHomePage":true,"disableExportNotebook":false,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","commandStatusDebounceInterval":100,"showSqlEndpoints":false,"enableNotebookDatasetInfoView":true,"defaultTagKeys":{"CLUSTER_NAME":"ClusterName","VENDOR":"Vendor","CLUSTER_TYPE":"ResourceClass","CREATOR":"Creator","CLUSTER_ID":"ClusterId"},"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","azurePortalLink":"https://portal.azure.com","cloud":"AWS","customSparkVersionPrefix":"custom:","disallowAddingAdmins":true,"enableSparkConfUI":true,"enableClusterEventsUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","defaultServerlessClusterModel":{"cluster_name":"","node_type_id":"i3.2xlarge","spark_version":"latest-stable-scala2.11","num_workers":null,"enable_jdbc_auto_start":true,"custom_tags":{"ResourceClass":"Serverless"},"autoscale":{"min_workers":2,"max_workers":20},"spark_conf":{"spark.databricks.cluster.profile":"serverless","spark.databricks.repl.allowedLanguages":"sql,python,r"},"aws_attributes":{"ebs_volume_count":null,"availability":"ON_DEMAND","first_on_demand":1,"ebs_volume_type":null,"spot_bid_price_percent":100,"zone_id":"us-west-2c","ebs_volume_size":null},"autotermination_minutes":0,"enable_elastic_disk":false,"default_tags":{"Vendor":"Databricks","Creator":"bombatkar.vivek@gmail.com","ClusterName":null,"ClusterId":"<Generated after creation>"}},"enableOrgSwitcherUI":true,"bitbucketCloudBaseApiV2Url":"https://api.bitbucket.org/2.0","clustersLimit":1,"enableJdbcImport":true,"enableClusterAppsUIOnNormalClusters":false,"enableElasticDisk":false,"logfiles":"logfiles/","enableRelativeNotebookLinks":true,"enableMultiSelect":true,"homePageLogo":"login/databricks_logoTM_rgb_TM.svg","enableWebappSharding":true,"enableNotebookParamsEdit":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"separateTableForJobClusters":true,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"enableRServerless":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"showVersion":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"","clusterTagReservedPrefixes":[],"tableAclsEnabledMap":{"spark.databricks.acl.dfAclsEnabled":"true","spark.databricks.repl.allowedLanguages":"python,sql"},"showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","databricksDocsNotebookPathPrefix":"^https://docs\\.databricks\\.com/_static/notebooks/.+$","serverlessAttachEbsVolumesByDefault":false,"enableTokensConfig":false,"allowFeedbackForumAccess":true,"enablePythonVersionUI":true,"enableImportFromUrl":true,"allowDisplayHtmlByUrl":true,"enableTokens":false,"enableMiniClusters":true,"enableNewJobList":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"loginLogo":"/login/databricks_logoTM_rgb_TM.svg","useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/","enableSpotClusterType":true,"enableSparkPackages":true,"checkAadUserInWorkspaceTenant":false,"dynamicSparkVersions":true,"useIframeForHtmlResult":false,"enableClusterTagsUIByTier":false,"enableUserPromptForPendingRpc":true,"enableNotebookHistoryUI":true,"addWhitespaceAfterLastNotebookCell":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"maxImportFileVersion":5,"enableEBSVolumesUIByTier":false,"enableTableAclService":true,"removeSubCommandCodeWhenExport":true,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"showResultsFromExternalSearchEngine":true,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":4270181377074593,"name":"LogisticRegression_Estimator_Transformer_Param","language":"python","commands":[{"version":"CommandV1","origId":4270181377074594,"guid":"cc0e19d5-6312-4300-8a27-43e97793d3fb","subtype":"command","commandType":"auto","position":1.0,"command":"%md # ML Pipelines with Spark ML\n\nThis example covers the concepts of Estimator, Transformer, and Param.\n\n\nPipelines API concept is mostly inspired by the scikit-learn project.\n\nhttps://spark.apache.org/docs/latest/ml-pipeline.html","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3616ee72-10e0-45e9-bd62-7d73b87e34bd"},{"version":"CommandV1","origId":4270181377074596,"guid":"638bf150-2385-443d-9f00-5d3ecdc5f2fb","subtype":"command","commandType":"auto","position":2.0,"command":"from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.classification import LogisticRegression","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523790560713,"submitTime":1523790516466,"finishTime":1523790560854,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"091be0ee-b8c1-41be-a75f-2ab0fcff0b7c"},{"version":"CommandV1","origId":4273395775263226,"guid":"64fbd832-3144-4f1d-856f-1723281d0d7c","subtype":"command","commandType":"auto","position":2.5,"command":"%md ## keywords\n\n* Vectors  : A vector has magnitude (size) and direction. Vectors are the metrics. A local vector has integer-typed and 0-based indices and double-typed values, stored on a single machine.\n\n* MLlib supports two types of local vectors: dense and sparse. A dense vector is backed by a double array representing its entry values, while a sparse vector is backed by two parallel arrays: indices and values. Being sparse means that it won’t explicitly contains each coordinate.\n\nEx. \n\n-a vector (1.0, 0.0, 3.0) can be represented in dense format as [1.0, 0.0, 3.0] or in sparse format as (3, [0, 2], [1.0, 3.0]), where 3 is the size of the vector.\n\n-dense vector (1, 2, 0, 0, 5, 0, 9, 0, 0) will be represented as sparse like {(0,1,4,6), (1, 2, 5, 9)}\n\n<br>\n\n* Transformers : converting datafeame into another dataframe\n\n-A feature transformer might take a DataFrame, read a column (e.g., text), map it into a new column (e.g., feature vectors), and output a new DataFrame with the mapped column appended.\n-A learning model might take a DataFrame, read the column containing feature vectors, predict the label for each feature vector, and output a new DataFrame with predicted labels appended as a column.\n\n<br>\n\n* Estimators: concept of a learning algorithm or any algorithm that fits or trains on data.  Technically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. \n\n-For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer.\n\n<br>\n\n* Pipeline\n\nIn the Machine Learning Process data runs through different Stages, e.g. StringIndexer, VectorAssembler, VectorIndexer and RandomForestClassifier. These Stages can be combined to one workflow with a Pipeline. The DataFrame as the central data structure will be enriched at each Stage of the Pipeline.\n\n<br>\n\n* There are 2 types of Stages:\n\n-Estimator creates a model by calling the fit() method, e.g. StringIndexer, VectorIndexer and RandomForestClassifier\n\n-Transformer is a model and transforms a DataFrame by usually adding columns to the Input-DataFrame\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6d1f606a-aa61-47b5-bc12-11409974a54f"},{"version":"CommandV1","origId":4270181377074599,"guid":"78b93736-9365-4740-9ce9-fac55e846f83","subtype":"command","commandType":"auto","position":3.0,"command":"# Prepare training data from a list of (label, features) tuples.\ndf_training = spark.createDataFrame([\n    (1.0, Vectors.dense([0.0, 1.1, 0.1])),\n    (0.0, Vectors.dense([2.0, 1.0, -1.0])),\n    (0.0, Vectors.dense([2.0, 1.3, 1.0])),\n    (1.0, Vectors.dense([0.0, 1.2, -0.5]))], [\"label\", \"features\"])","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"df_training","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523791055395,"submitTime":1523791055387,"finishTime":1523791055834,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6f398fe4-09d8-423a-989c-c070d5f547b2"},{"version":"CommandV1","origId":4273395775263228,"guid":"29e7fd71-40c8-49a1-bb61-3e21ce74be49","subtype":"command","commandType":"auto","position":3.25,"command":"%md # features and lables\n\nBriefly, feature is input; label is output.\n\nA feature is one column of the data in your input set. For instance, if you're trying to predict the type of pet someone will choose, your input features might include age, home region, family income, etc. The label is the final choice, such as dog, fish, iguana, rock, etc.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"84155b90-595c-42c8-9f29-99912d28d770"},{"version":"CommandV1","origId":4273395775263227,"guid":"1d224ff1-bf37-4375-87e5-a5cc1b47fef9","subtype":"command","commandType":"auto","position":3.5,"command":"#the training dataset\ndf_training.show()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">+-----+--------------+\n|label|      features|\n+-----+--------------+\n|  1.0| [0.0,1.1,0.1]|\n|  0.0|[2.0,1.0,-1.0]|\n|  0.0| [2.0,1.3,1.0]|\n|  1.0|[0.0,1.2,-0.5]|\n+-----+--------------+\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523791631407,"submitTime":1523791631402,"finishTime":1523791631744,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"e57a46b4-c642-419d-9b90-bf9d13abd95b"},{"version":"CommandV1","origId":4270181377074600,"guid":"9ce69881-9569-4734-ae82-1fd483391e39","subtype":"command","commandType":"auto","position":4.0,"command":"# Create a LogisticRegression instance. This instance is an Estimator.\nlr = LogisticRegression(maxIter=10, regParam=0.01)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523791100549,"submitTime":1523791100542,"finishTime":1523791100726,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3a0f516a-a990-4ff6-b21f-896f4b8f71f2"},{"version":"CommandV1","origId":2030776248230506,"guid":"311f3755-f3f7-4b1d-b82e-a4416e83e014","subtype":"command","commandType":"auto","position":4.5,"command":"%md ## Logistic Regression\n\n\n* is widely used to predict a binary response.\n* is used to ascertain the probability of an event. And this event is captured in binary format, i.e. 0 or 1.\n* Example - I want to ascertain if a customer will buy my product or not. For this, I would run a Logistic Regression on the (relevant) data and my dependent variable would be a binary variable (1=Yes; 0=No).\n* that is, where the output can take only two values, \"0\" and \"1\", which represent outcomes such as pass/fail, win/lose, alive/dead or healthy/sick.\n* maxIter -  The number of iterations.\n* regParam - The regularizer parameter\n\n\n## Linear Regression\n\n * is used to establish a relationship between Dependent and Independent variables, which is useful in estimating the resultant dependent variable in case independent variable change.\n\n\n<br>\n\n* In terms of graphical representation, Linear Regression gives a linear line as an output, once the values are plotted on the graph. Whereas, the logistic regression gives an S-shaped line","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c153346d-8dde-46b6-ac67-e8e4611c6273"},{"version":"CommandV1","origId":4270181377074601,"guid":"af8185fd-6759-469b-9448-821e83bc25a2","subtype":"command","commandType":"auto","position":5.0,"command":"# Print out the parameters, documentation, and any default values.\nprint(\"LogisticRegression parameters:\\n\" + lr.explainParams() + \"\\n\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">LogisticRegression parameters:\naggregationDepth: suggested depth for treeAggregate (&gt;= 2). (default: 2)\nelasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\nfamily: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\nfeaturesCol: features column name. (default: features)\nfitIntercept: whether to fit an intercept term. (default: True)\nlabelCol: label column name. (default: label)\nlowerBoundsOnCoefficients: The lower bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\nlowerBoundsOnIntercepts: The lower bounds on intercepts if fitting under bound constrained optimization. The bounds vector size must beequal with 1 for binomial regression, or the number oflasses for multinomial regression. (undefined)\nmaxIter: max number of iterations (&gt;= 0). (default: 100, current: 10)\npredictionCol: prediction column name. (default: prediction)\nprobabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\nrawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\nregParam: regularization parameter (&gt;= 0). (default: 0.0, current: 0.01)\nstandardization: whether to standardize the training features before fitting the model. (default: True)\nthreshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\nthresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values &gt; 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class&apos;s threshold. (undefined)\ntol: the convergence tolerance for iterative algorithms (&gt;= 0). (default: 1e-06)\nupperBoundsOnCoefficients: The upper bounds on coefficients if fitting under bound constrained optimization. The bound matrix must be compatible with the shape (1, number of features) for binomial regression, or (number of classes, number of features) for multinomial regression. (undefined)\nupperBoundsOnIntercepts: The upper bounds on intercepts if fitting under bound constrained optimization. The bound vector size must be equal with 1 for binomial regression, or the number of classes for multinomial regression. (undefined)\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;lr&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4270181377074601&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Print out the parameters, documentation, and any default values.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;LogisticRegression parameters:\\n&quot;</span> <span class=\"ansiyellow\">+</span> lr<span class=\"ansiyellow\">.</span>explainParams<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span> <span class=\"ansiyellow\">+</span> <span class=\"ansiblue\">&quot;\\n&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;lr&apos; is not defined</div>","workflows":[],"startTime":1523791105933,"submitTime":1523791105927,"finishTime":1523791105975,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b3738ddc-e708-403f-99a4-89d1ee202876"},{"version":"CommandV1","origId":2030776248230509,"guid":"72f77996-7d82-4b40-ae84-36e96d4b8e01","subtype":"command","commandType":"auto","position":5.5,"command":"%md\n - explainParams() - Returns the documentation of all params with their optionally default values and user-supplied values.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0c257e54-4d25-4084-9b00-8e2f4df2e6e7"},{"version":"CommandV1","origId":4270181377074602,"guid":"88ac49ea-4c80-4df2-b5df-723726d200fe","subtype":"command","commandType":"auto","position":6.0,"command":"# Learn a LogisticRegression model. This uses the parameters stored in lr.\nmodel1 = lr.fit(df_training)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;training&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4270181377074602&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Learn a LogisticRegression model. This uses the parameters stored in lr.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>model1 <span class=\"ansiyellow\">=</span> lr<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>training<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;training&apos; is not defined</div>","workflows":[],"startTime":1523791112964,"submitTime":1523791112958,"finishTime":1523791116629,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"2267d12f-2bbc-4dec-9756-b0f9da9342c9"},{"version":"CommandV1","origId":2030776248230510,"guid":"096769c1-80aa-4548-bcc5-c639125a632e","subtype":"command","commandType":"auto","position":6.5,"command":"%md \n* fit(dataset, params=None) \n\nFits a model to the input dataset with optional parameters.\n\nReturns the fitted model(s)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"50534aa4-29ac-4263-a1a3-9c9827accdb3"},{"version":"CommandV1","origId":2742494105125903,"guid":"ac51ebd7-5ad1-4317-9a1e-624bafa56313","subtype":"command","commandType":"auto","position":6.75,"command":"model1.write().overwrite().save(\"/FileStore/tables/modle1\")","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"java.io.IOException: Path /FileStore/tables/modle1 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-2742494105125903&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>model1<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;/FileStore/tables/modle1&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/util.py</span> in <span class=\"ansicyan\">save</span><span class=\"ansiblue\">(self, path)</span>\n<span class=\"ansigreen\">    202</span>     <span class=\"ansigreen\">def</span> save<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    203</span>         <span class=\"ansiblue\">&quot;&quot;&quot;Save this ML instance to the given path, a shortcut of &apos;write().save(path)&apos;.&quot;&quot;&quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 204</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>write<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    205</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    206</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/ml/util.py</span> in <span class=\"ansicyan\">save</span><span class=\"ansiblue\">(self, path)</span>\n<span class=\"ansigreen\">    163</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> isinstance<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">,</span> basestring<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    164</span>             <span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;path should be a basestring, got type %s&quot;</span> <span class=\"ansiyellow\">%</span> type<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 165</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>_jwrite<span class=\"ansiyellow\">.</span>save<span class=\"ansiyellow\">(</span>path<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    166</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    167</span>     <span class=\"ansigreen\">def</span> overwrite<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.6-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1158</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1159</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1160</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1161</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1162</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.6-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    318</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    319</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 320</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    321</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    322</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling o445.save.\n: java.io.IOException: Path /FileStore/tables/modle1 already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:503)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:102)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:226)\n\tat java.lang.Thread.run(Thread.java:748)\n</div>","workflows":[],"startTime":1523792207154,"submitTime":1523792207148,"finishTime":1523792210678,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b435fc33-bce2-4997-92ec-e5e1577cd027"},{"version":"CommandV1","origId":2742494105125906,"guid":"8d50b2c8-5be8-4f62-aab0-adda5a1122a4","subtype":"command","commandType":"auto","position":6.8125,"command":"%md The result of save for pipeline model is a JSON file for metadata while Parquet for model data, e.g. coefficients.\n\n ","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"ab0ae433-3290-45e2-8c70-91e129898c36"},{"version":"CommandV1","origId":2742494105125904,"guid":"d0b35044-36d0-4ae0-bf6d-2b2c1bbcff21","subtype":"command","commandType":"auto","position":6.875,"command":"%fs ls /FileStore/tables/modle1/data","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/FileStore/tables/modle1/data/_SUCCESS","_SUCCESS",0],["dbfs:/FileStore/tables/modle1/data/_committed_6344610780192366248","_committed_6344610780192366248",122],["dbfs:/FileStore/tables/modle1/data/_started_6344610780192366248","_started_6344610780192366248",0],["dbfs:/FileStore/tables/modle1/data/part-00000-tid-6344610780192366248-71efd7d1-6830-4c3c-8f6a-bacc284fff6f-144-c000.snappy.parquet","part-00000-tid-6344610780192366248-71efd7d1-6830-4c3c-8f6a-bacc284fff6f-144-c000.snappy.parquet",3851]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null,"datasetInfos":[],"columnCustomDisplayInfos":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":1523792581959,"submitTime":1523792581949,"finishTime":1523792582404,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1d5a1fa7-de00-4095-a837-8b50bfd2cbdc"},{"version":"CommandV1","origId":2742494105125908,"guid":"36e31df0-ca6c-417f-be57-1051cb8a48d5","subtype":"command","commandType":"auto","position":6.90625,"command":"%fs head FileStore/tables/modle1/data/part-00000-tid-6344610780192366248-71efd7d1-6830-4c3c-8f6a-bacc284fff6f-144-c000.snappy.parquet","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">PAR1,,,\n$,6,6\r0*.,�o�tt�?�o�tt�?P�o�tt�?,\n$,\n$,\n$,6\r0,6\r0JL,?IP���@S���%d?S���?IP���@o|��Tؿ,,�Hspark_schema\n%\nnumClasses%numFeatures5interceptVector%type%%size5indices5list%element5values5list\n%element5coefficientMatrix%type%%numRows%numCols5colPtrs5list%element5\nrowIndices5list%element5values5list\n%element%isTransposed%\risMultinomial�&amp;%\nnumClassesJN&amp;&lt;&amp;V%numFeaturesJN&amp;V&lt;&amp;�5(interceptVectortypeVZ&amp;�&lt;&amp;�5(interceptVectorsize8&lt;&amp;�&lt;6&amp;�%HinterceptVectorindiceslistelementDH&amp;�&lt;6&amp;�\n%HinterceptVectorvalueslistelement|�&amp;�&lt;�o�tt�?�o�tt�?&amp;�5(coefficientMatrixtypeVZ&amp;�&lt;&amp;�5(coefficientMatrixnumRowsVZ&amp;�&lt;&amp;�5(coefficientMatrixnumColsVZ&amp;�&lt;&amp;�%HcoefficientMatrixcolPtrslistelementDH&amp;�&lt;6&amp;�%HcoefficientMatrix\nrowIndiceslistelementDH&amp;�&lt;6&amp;�\n%HcoefficientMatrixvalueslistelement��&amp;�&lt;?IP���@S���&amp;�5(coefficientMatrixisTransposedDH&amp;�&lt;&amp;�\t%\risMultinomial8&lt;&amp;�\t&lt;�\t)org.apache.spark.sql.parquet.row.metadata�{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;numClasses&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;numFeatures&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;interceptVector&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;udt&quot;,&quot;class&quot;:&quot;org.apache.spark.ml.linalg.VectorUDT&quot;,&quot;pyClass&quot;:&quot;pyspark.ml.linalg.VectorUDT&quot;,&quot;sqlType&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;type&quot;,&quot;type&quot;:&quot;byte&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;size&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;indices&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;elementType&quot;:&quot;integer&quot;,&quot;containsNull&quot;:false},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;values&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;elementType&quot;:&quot;double&quot;,&quot;containsNull&quot;:false},&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;coefficientMatrix&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;udt&quot;,&quot;class&quot;:&quot;org.apache.spark.ml.linalg.MatrixUDT&quot;,&quot;pyClass&quot;:&quot;pyspark.ml.linalg.MatrixUDT&quot;,&quot;sqlType&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;type&quot;,&quot;type&quot;:&quot;byte&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;numRows&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;numCols&quot;,&quot;type&quot;:&quot;integer&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;colPtrs&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;elementType&quot;:&quot;integer&quot;,&quot;containsNull&quot;:false},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;rowIndices&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;elementType&quot;:&quot;integer&quot;,&quot;containsNull&quot;:false},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;values&quot;,&quot;type&quot;:{&quot;type&quot;:&quot;array&quot;,&quot;elementType&quot;:&quot;double&quot;,&quot;containsNull&quot;:false},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;isTransposed&quot;,&quot;type&quot;:&quot;boolean&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}}]}},&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;isMultinomial&quot;,&quot;type&quot;:&quot;boolean&quot;,&quot;nullable&quot;:false,&quot;metadata&quot;:{}}]}Uparquet-mr version 1.8.2-databricks1 (build 9a712134668e45605c37c82134537baf617ead0d)�PAR1\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523792596222,"submitTime":1523792596216,"finishTime":1523792596554,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"df8b2279-d467-48ee-be93-1482b947ac43"},{"version":"CommandV1","origId":2742494105125905,"guid":"a77e5902-d2c4-4f90-b462-b2d4465b2761","subtype":"command","commandType":"auto","position":6.9375,"command":"%fs ls /FileStore/tables/modle1/metadata","commandVersion":0,"state":"finished","results":{"type":"table","data":[["dbfs:/FileStore/tables/modle1/metadata/_SUCCESS","_SUCCESS",0],["dbfs:/FileStore/tables/modle1/metadata/part-00000","part-00000",480]],"arguments":{},"addedWidgets":{},"removedWidgets":[],"schema":[{"name":"path","type":"\"string\"","metadata":"{}"},{"name":"name","type":"\"string\"","metadata":"{}"},{"name":"size","type":"\"long\"","metadata":"{}"}],"overflow":false,"aggData":[],"aggSchema":[],"aggOverflow":false,"aggSeriesLimitReached":false,"aggError":"","aggType":"","plotOptions":null,"isJsonSchema":true,"dbfsResultPath":null,"datasetInfos":[],"columnCustomDisplayInfos":{}},"errorSummary":null,"error":null,"workflows":[],"startTime":1523792382780,"submitTime":1523792382773,"finishTime":1523792383282,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"07870705-fff4-4c7d-ab6d-8fec49bc4b52"},{"version":"CommandV1","origId":2742494105125907,"guid":"4396b91e-e157-4804-93db-3e4182338ba9","subtype":"command","commandType":"auto","position":6.96875,"command":"%fs head /FileStore/tables/modle1/metadata/part-00000 ","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">{&quot;class&quot;:&quot;org.apache.spark.ml.classification.LogisticRegressionModel&quot;,&quot;timestamp&quot;:1523792208761,&quot;sparkVersion&quot;:&quot;2.3.0&quot;,&quot;uid&quot;:&quot;LogisticRegression_449594a8294ec9335a58&quot;,&quot;paramMap&quot;:{&quot;labelCol&quot;:&quot;label&quot;,&quot;probabilityCol&quot;:&quot;probability&quot;,&quot;aggregationDepth&quot;:2,&quot;regParam&quot;:0.01,&quot;rawPredictionCol&quot;:&quot;rawPrediction&quot;,&quot;threshold&quot;:0.5,&quot;tol&quot;:1.0E-6,&quot;featuresCol&quot;:&quot;features&quot;,&quot;fitIntercept&quot;:true,&quot;standardization&quot;:true,&quot;maxIter&quot;:10,&quot;predictionCol&quot;:&quot;prediction&quot;,&quot;family&quot;:&quot;auto&quot;,&quot;elasticNetParam&quot;:0.0}}\n\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<div class=\"ansiout\">notebook:1: error: value more is not a member of com.databricks.dbutils_v1.DbfsUtils\ndbutils.fs.more(&quot;/FileStore/tables/modle1/metadata/part-00000&quot;)\n           ^\n</div>","error":null,"workflows":[],"startTime":1523792482441,"submitTime":1523792482440,"finishTime":1523792482664,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"c9ab0e7f-5eb8-475f-81cc-992667a6f03b"},{"version":"CommandV1","origId":4270181377074603,"guid":"733e31de-7992-4d41-8e27-310dc201b979","subtype":"command","commandType":"auto","position":7.0,"command":"# Since model1 is a Model (i.e., a transformer produced by an Estimator),\n# we can view the parameters it used during fit().\n# This prints the parameter (name: value) pairs, where names are unique IDs for this\n# LogisticRegression instance.\nprint(\"Model 1 was fit using parameters: \")\nprint(model1.extractParamMap())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Model 1 was fit using parameters: \n{Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;aggregationDepth&apos;, doc=&apos;suggested depth for treeAggregate (&gt;= 2)&apos;): 2, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;probabilityCol&apos;, doc=&apos;Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities&apos;): &apos;probability&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;fitIntercept&apos;, doc=&apos;whether to fit an intercept term&apos;): True, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;predictionCol&apos;, doc=&apos;prediction column name&apos;): &apos;prediction&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;labelCol&apos;, doc=&apos;label column name&apos;): &apos;label&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;rawPredictionCol&apos;, doc=&apos;raw prediction (a.k.a. confidence) column name&apos;): &apos;rawPrediction&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;featuresCol&apos;, doc=&apos;features column name&apos;): &apos;features&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;family&apos;, doc=&apos;The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.&apos;): &apos;auto&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;standardization&apos;, doc=&apos;whether to standardize the training features before fitting the model&apos;): True, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;threshold&apos;, doc=&apos;threshold in binary classification prediction, in range [0, 1]&apos;): 0.5, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;elasticNetParam&apos;, doc=&apos;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty&apos;): 0.0, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;maxIter&apos;, doc=&apos;maximum number of iterations (&gt;= 0)&apos;): 10, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;tol&apos;, doc=&apos;the convergence tolerance for iterative algorithms (&gt;= 0)&apos;): 1e-06, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;regParam&apos;, doc=&apos;regularization parameter (&gt;= 0)&apos;): 0.01}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523736464906,"submitTime":1523736464895,"finishTime":1523736464984,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"3dedadcc-0dcc-453d-b700-a902be8b3be8"},{"version":"CommandV1","origId":2030776248230511,"guid":"205570d0-8f42-4ded-8dd6-43dec627b5f9","subtype":"command","commandType":"auto","position":7.5,"command":"%md \n* extractParamMap\n\nExtracts the embedded default param values and user-supplied values, and then merges them with extra values from input into a flat param map, where the latter value is used if there exist conflicts, i.e., with ordering: default param values < user-supplied values < extra.\n\nReturns the\tmerged param map","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"93047cd0-959d-4c4f-bdf3-2c5581896a39"},{"version":"CommandV1","origId":4270181377074604,"guid":"768bb3a7-6ca9-4ae0-b93a-964beaf850a5","subtype":"command","commandType":"auto","position":8.0,"command":"# We may alternatively specify parameters using a Python dictionary as a paramMap\nparamMap = {lr.maxIter: 20}\nparamMap[lr.maxIter] = 30  # Specify 1 Param, overwriting the original maxIter.\nparamMap.update({lr.regParam: 0.1, lr.threshold: 0.55})  # Specify multiple Params.","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523737372596,"submitTime":1523737372585,"finishTime":1523737372638,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0b3c224c-68a7-462e-ac58-940be6ebd9e8"},{"version":"CommandV1","origId":4270181377074605,"guid":"ef23b614-42be-457b-b655-5927ec4dce9a","subtype":"command","commandType":"auto","position":9.0,"command":"# You can combine paramMaps, which are python dictionaries.\nparamMap2 = {lr.probabilityCol: \"myProbability\"}  # Change output column name\nparamMapCombined = paramMap.copy()\nparamMapCombined.update(paramMap2)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523737374569,"submitTime":1523737374559,"finishTime":1523737374611,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5fbe962c-76c4-4784-8347-97a80c2e4e17"},{"version":"CommandV1","origId":4270181377074606,"guid":"b5174ab5-f407-45da-b08e-de3f881061aa","subtype":"command","commandType":"auto","position":10.0,"command":"# Now learn a new model using the paramMapCombined parameters.\n# paramMapCombined overrides all parameters set earlier via lr.set* methods.\nmodel2 = lr.fit(df_training, paramMapCombined)\nprint(\"Model 2 was fit using parameters: \")\nprint(model2.extractParamMap())","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Model 2 was fit using parameters: \n{Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;aggregationDepth&apos;, doc=&apos;suggested depth for treeAggregate (&gt;= 2)&apos;): 2, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;probabilityCol&apos;, doc=&apos;Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities&apos;): &apos;myProbability&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;fitIntercept&apos;, doc=&apos;whether to fit an intercept term&apos;): True, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;predictionCol&apos;, doc=&apos;prediction column name&apos;): &apos;prediction&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;labelCol&apos;, doc=&apos;label column name&apos;): &apos;label&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;rawPredictionCol&apos;, doc=&apos;raw prediction (a.k.a. confidence) column name&apos;): &apos;rawPrediction&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;featuresCol&apos;, doc=&apos;features column name&apos;): &apos;features&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;family&apos;, doc=&apos;The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial.&apos;): &apos;auto&apos;, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;standardization&apos;, doc=&apos;whether to standardize the training features before fitting the model&apos;): True, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;threshold&apos;, doc=&apos;threshold in binary classification prediction, in range [0, 1]&apos;): 0.55, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;elasticNetParam&apos;, doc=&apos;the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty&apos;): 0.0, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;maxIter&apos;, doc=&apos;maximum number of iterations (&gt;= 0)&apos;): 30, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;tol&apos;, doc=&apos;the convergence tolerance for iterative algorithms (&gt;= 0)&apos;): 1e-06, Param(parent=u&apos;LogisticRegression_46ab87b370e681ed05d1&apos;, name=&apos;regParam&apos;, doc=&apos;regularization parameter (&gt;= 0)&apos;): 0.1}\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;training&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4270181377074606&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Now learn a new model using the paramMapCombined parameters.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> <span class=\"ansired\"># paramMapCombined overrides all parameters set earlier via lr.set* methods.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>model2 <span class=\"ansiyellow\">=</span> lr<span class=\"ansiyellow\">.</span>fit<span class=\"ansiyellow\">(</span>training<span class=\"ansiyellow\">,</span> paramMapCombined<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Model 2 was fit using parameters: &quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      5</span> <span class=\"ansigreen\">print</span><span class=\"ansiyellow\">(</span>model2<span class=\"ansiyellow\">.</span>extractParamMap<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;training&apos; is not defined</div>","workflows":[],"startTime":1523737375914,"submitTime":1523737375903,"finishTime":1523737379251,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"029fccde-5669-42aa-8a94-6b665c583391"},{"version":"CommandV1","origId":4270181377074607,"guid":"3c8f068f-56de-4487-a0ec-fc499d4119d3","subtype":"command","commandType":"auto","position":11.0,"command":"# the input dataset\n# Prepare test data\ndf_test = spark.createDataFrame([\n    (1.0, Vectors.dense([-1.0, 1.5, 1.3])),\n    (0.0, Vectors.dense([3.0, 2.0, -0.1])),\n    (1.0, Vectors.dense([0.0, 2.2, -1.5]))], [\"label\", \"features\"])","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"df_test","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523737385409,"submitTime":1523737385389,"finishTime":1523737385534,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"b6887d8c-6d58-4ff8-b7ad-553d9b3c7076"},{"version":"CommandV1","origId":4270181377074608,"guid":"c17e892d-eebe-4415-914a-fc91b8d354dc","subtype":"command","commandType":"auto","position":12.0,"command":"# Make predictions on test data using the Transformer.transform() method.\n# LogisticRegression.transform will only use the 'features' column.\n# Note that model2.transform() outputs a \"myProbability\" column instead of the usual\n# 'probability' column since we renamed the lr.probabilityCol parameter previously.\nprediction = model2.transform(df_test)\nresult = prediction.select(\"features\", \"label\", \"myProbability\", \"prediction\") \\\n    .collect()","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[{"name":"prediction","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"label","nullable":true,"type":"double"},{"metadata":{},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"rawPrediction","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"myProbability","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"prediction","nullable":false,"type":"double"}],"type":"struct"},"tableIdentifier":null}]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;model2&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-4270181377074608&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      3</span> <span class=\"ansired\"># Note that model2.transform() outputs a &quot;myProbability&quot; column instead of the usual</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansired\"># &apos;probability&apos; column since we renamed the lr.probabilityCol parameter previously.</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 5</span><span class=\"ansiyellow\"> </span>prediction <span class=\"ansiyellow\">=</span> model2<span class=\"ansiyellow\">.</span>transform<span class=\"ansiyellow\">(</span>df_test<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      6</span> result <span class=\"ansiyellow\">=</span> prediction<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;features&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;label&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;myProbability&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;prediction&quot;</span><span class=\"ansiyellow\">)</span>     <span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;model2&apos; is not defined</div>","workflows":[],"startTime":1523737389396,"submitTime":1523737389385,"finishTime":1523737389892,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"cf7c60be-36d4-48c3-b9f6-f1d84619d681"},{"version":"CommandV1","origId":2030776248230512,"guid":"866ff1b4-5083-417e-b78b-a3041c90abeb","subtype":"command","commandType":"auto","position":12.5,"command":"%md \n* transform - Transforms the input dataset with optional parameters.\n\nParameters:\t\n\ndataset – input dataset, which is an instance of pyspark.sql.DataFrame\n\nparams – an optional param map that overrides embedded params.\n\nReturns the transformed dataset","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"5e887469-f63f-4203-be9d-6a944dd88cdb"},{"version":"CommandV1","origId":4270181377074609,"guid":"6b82e9a6-f5e0-49a4-878e-80cb4c666b49","subtype":"command","commandType":"auto","position":13.0,"command":"for row in result:\n    print(\"features=%s, label=%s -> prob=%s, prediction=%s\"\n          % (row.features, row.label, row.myProbability, row.prediction))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">features=[-1.0,1.5,1.3], label=1.0 -&gt; prob=[0.0570730417103,0.94292695829], prediction=1.0\nfeatures=[3.0,2.0,-0.1], label=0.0 -&gt; prob=[0.92385223117,0.0761477688296], prediction=0.0\nfeatures=[0.0,2.2,-1.5], label=1.0 -&gt; prob=[0.109727761148,0.890272238852], prediction=1.0\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1523737762667,"submitTime":1523737762658,"finishTime":1523737762694,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"886dd709-2891-4e8c-8312-79cce5ce1f04"}],"dashboards":[],"guid":"029f9bf6-6179-40d3-8756-96665a658136","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/js/metrics-graphics.js"
 onerror="window.mainJsLoadError = true;"></script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/dafda9f3df7d430fbaa0fa5d28080bc75e59001c1b8e417cba4151789385b12c/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>
